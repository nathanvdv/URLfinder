{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning BERT for URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium>=3.141.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 1)) (4.16.0)\n",
      "Requirement already satisfied: webdriver-manager>=3.4.2 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 2)) (4.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 3)) (2.1.4)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 5)) (3.8.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 7)) (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 8)) (2.31.0)\n",
      "Requirement already satisfied: duckduckgo_search in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 9)) (5.3.0)\n",
      "Requirement already satisfied: ratelimit in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 10)) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 11)) (1.4.1.post1)\n",
      "Requirement already satisfied: keras in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 12)) (3.2.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 13)) (2.16.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 14)) (4.39.3)\n",
      "Requirement already satisfied: torch in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 15)) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 16)) (1.26.3)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 17)) (0.15.2)\n",
      "Collecting torchaudio (from -r requirements.txt (line 18))\n",
      "  Downloading torchaudio-2.2.2-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting torchvision (from -r requirements.txt (line 19))\n",
      "  Downloading torchvision-0.17.2-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from -r requirements.txt (line 20)) (4.66.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=3.141.0->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from selenium>=3.141.0->-r requirements.txt (line 1)) (0.23.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from selenium>=3.141.0->-r requirements.txt (line 1)) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from selenium>=3.141.0->-r requirements.txt (line 1)) (2023.11.17)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from webdriver-manager>=3.4.2->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from webdriver-manager>=3.4.2->-r requirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 7)) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from requests->-r requirements.txt (line 8)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from requests->-r requirements.txt (line 8)) (3.6)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from duckduckgo_search->-r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: curl-cffi>=0.6.2 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from duckduckgo_search->-r requirements.txt (line 9)) (0.6.2)\n",
      "Requirement already satisfied: orjson>=3.10.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from duckduckgo_search->-r requirements.txt (line 9)) (3.10.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 11)) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 11)) (3.4.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from keras->-r requirements.txt (line 12)) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from keras->-r requirements.txt (line 12)) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from keras->-r requirements.txt (line 12)) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from keras->-r requirements.txt (line 12)) (3.10.0)\n",
      "Requirement already satisfied: optree in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from keras->-r requirements.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from keras->-r requirements.txt (line 12)) (0.3.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (2.16.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (2.16.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from transformers->-r requirements.txt (line 14)) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from transformers->-r requirements.txt (line 14)) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from transformers->-r requirements.txt (line 14)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from transformers->-r requirements.txt (line 14)) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from transformers->-r requirements.txt (line 14)) (0.4.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from torch->-r requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from torch->-r requirements.txt (line 15)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from torch->-r requirements.txt (line 15)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from torch->-r requirements.txt (line 15)) (2024.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tqdm->-r requirements.txt (line 20)) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from curl-cffi>=0.6.2->duckduckgo_search->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from trio~=0.17->selenium>=3.141.0->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from trio~=0.17->selenium>=3.141.0->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from trio~=0.17->selenium>=3.141.0->-r requirements.txt (line 1)) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from trio~=0.17->selenium>=3.141.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from trio-websocket~=0.9->selenium>=3.141.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=3.141.0->-r requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 15)) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from rich->keras->-r requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from rich->keras->-r requirements.txt (line 12)) (2.17.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 15)) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (0.41.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from cffi>=1.12.0->curl-cffi>=0.6.2->duckduckgo_search->-r requirements.txt (line 9)) (2.21)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->-r requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 13)) (3.0.2)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\natha\\anaconda3\\envs\\urlfinder\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=3.141.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Downloading torchaudio-2.2.2-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 2.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.4 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.4 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.2/2.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.5/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.9/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.0/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.17.2-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.2 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.9/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.1/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.2.2 torchvision-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EntityNumber                                        SearchQuery  \\\n",
      "0  0201.310.929                                      IGL 3600 Genk   \n",
      "1  0202.239.951                           PROXIMUS 1030 Schaarbeek   \n",
      "2  0203.201.340             Nationale Bank van België 1000 Brussel   \n",
      "3  0206.460.639  Intergemeentelijk Samenwerkingsverband van het...   \n",
      "4  0206.653.946  Rijksinstituut voor Ziekte- en Invaliditeitsve...   \n",
      "\n",
      "           CorrectDomain             URL1Domain      URL2Domain  \\\n",
      "0  extranet.iglimburg.be           iglimburg.be  intergalva.com   \n",
      "1           proximus.com           proximus.com     proximus.be   \n",
      "2                 nbb.be                 nbb.be          nbb.be   \n",
      "3           interwaas.be  erfgoedcelwaasland.be         vvsg.be   \n",
      "4          inami.fgov.be          riziv.fgov.be   riziv.fgov.be   \n",
      "\n",
      "      URL3Domain               URL4Domain         URL5Domain           Labels  \n",
      "0   mapcarta.com       roamtechnology.com         geruro.com  [0, 0, 0, 0, 0]  \n",
      "1    proximus.be             proximus.com        proximus.be  [1, 0, 0, 1, 0]  \n",
      "2   nbbmuseum.be  openingsuren.vlaanderen       nbbmuseum.be  [1, 1, 0, 0, 0]  \n",
      "3    govserv.org           creditsafe.com            fsma.be  [0, 0, 0, 0, 0]  \n",
      "4  riziv.fgov.be         sociaal.brussels  desocialekaart.be  [0, 0, 0, 0, 0]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Function to preprocess and extract domain from URLs\n",
    "def extract_domain(url):\n",
    "    # Check if the URL is not a string (e.g., NaN or None)\n",
    "    if not isinstance(url, str):\n",
    "        return \"\"  # Return an empty string to indicate no domain\n",
    "        # Clean the URL by removing slashes and quotation marks\n",
    "    \n",
    "    # Extract the domain\n",
    "    parsed_url = urlparse(url)\n",
    "    domain = parsed_url.netloc or parsed_url.path  # Fallback to path if netloc is empty (e.g., relative URLs)\n",
    "    domain = domain.replace('www.', '')  # Removing 'www.' for consistency\n",
    "    domain = domain.replace('/', '').replace('\"', '')\n",
    "    return domain\n",
    "\n",
    "# Load the datasets\n",
    "dataset_query = pd.read_csv('dataset_incl_query.csv')\n",
    "dataset_scraped = pd.read_csv('search_results_DDG.csv')\n",
    "\n",
    "# Merge datasets on 'EntityNumber'\n",
    "merged_dataset = pd.merge(dataset_query[['EntityNumber', 'URL', 'SearchQuery']], dataset_scraped, on='EntityNumber')\n",
    "\n",
    "# Preprocess URLs to extract domains\n",
    "merged_dataset['CorrectDomain'] = merged_dataset['URL'].apply(extract_domain)\n",
    "for i in range(1, 6):\n",
    "    merged_dataset[f'URL{i}Domain'] = merged_dataset[f'URL{i}'].apply(extract_domain)\n",
    "\n",
    "# Prepare labels: If the correct domain matches one of the scraped domains, label with that index; otherwise, label as -1\n",
    "# Adjust the labeling function to handle multiple correct URLs\n",
    "def mark_correct_labels(row):\n",
    "    labels = []\n",
    "    for i in range(1, 6):\n",
    "        # Check if each scraped domain matches the correct domain\n",
    "        if row['CorrectDomain'] == row[f'URL{i}Domain']:\n",
    "            labels.append(1)  # Mark as correct\n",
    "        else:\n",
    "            labels.append(0)  # Mark as incorrect\n",
    "    return labels\n",
    "\n",
    "# Apply the function to each row in the merged dataset\n",
    "merged_dataset['Labels'] = merged_dataset.apply(mark_correct_labels, axis=1)\n",
    "\n",
    "# Display the updated dataset with domains and new labels for inspection\n",
    "print(merged_dataset[['EntityNumber', 'SearchQuery', 'CorrectDomain', 'URL1Domain', 'URL2Domain', 'URL3Domain', 'URL4Domain', 'URL5Domain', 'Labels']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EntityNumber                                        SearchQuery  \\\n",
      "0  0201.310.929                                      IGL 3600 Genk   \n",
      "1  0202.239.951                           PROXIMUS 1030 Schaarbeek   \n",
      "2  0203.201.340             Nationale Bank van België 1000 Brussel   \n",
      "3  0206.460.639  Intergemeentelijk Samenwerkingsverband van het...   \n",
      "4  0206.653.946  Rijksinstituut voor Ziekte- en Invaliditeitsve...   \n",
      "\n",
      "           CorrectDomain             URL1Domain      URL2Domain  \\\n",
      "0  extranet.iglimburg.be           iglimburg.be  intergalva.com   \n",
      "1           proximus.com           proximus.com     proximus.be   \n",
      "2                 nbb.be                 nbb.be          nbb.be   \n",
      "3           interwaas.be  erfgoedcelwaasland.be         vvsg.be   \n",
      "4          inami.fgov.be          riziv.fgov.be   riziv.fgov.be   \n",
      "\n",
      "      URL3Domain               URL4Domain         URL5Domain           Labels  \n",
      "0   mapcarta.com       roamtechnology.com         geruro.com  [0, 0, 0, 0, 0]  \n",
      "1    proximus.be             proximus.com        proximus.be  [1, 0, 0, 1, 0]  \n",
      "2   nbbmuseum.be  openingsuren.vlaanderen       nbbmuseum.be  [1, 1, 0, 0, 0]  \n",
      "3    govserv.org           creditsafe.com            fsma.be  [0, 0, 0, 0, 0]  \n",
      "4  riziv.fgov.be         sociaal.brussels  desocialekaart.be  [0, 0, 0, 0, 0]  \n"
     ]
    }
   ],
   "source": [
    "merged_dataset = merged_dataset.drop(['URL', 'URL1', 'URL2', 'URL3', 'URL4', 'URL5'], axis=1)\n",
    "print(merged_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prepreration for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLDomainDataset(Dataset):\n",
    "    def __init__(self, queries, domains, labels, tokenizer, max_len=512):\n",
    "        self.queries = queries\n",
    "        self.domains = domains\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query = self.queries[idx]\n",
    "        labels = self.labels[idx]\n",
    "        input_ids_list = []\n",
    "        attention_mask_list = []\n",
    "\n",
    "        for domain in self.domains[idx]:\n",
    "            # Tokenize query and domain\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                query + \" [SEP] \" + domain,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            input_ids_list.append(inputs[\"input_ids\"].squeeze(0))\n",
    "            attention_mask_list.append(inputs[\"attention_mask\"].squeeze(0))\n",
    "\n",
    "        input_ids = torch.stack(input_ids_list)\n",
    "        attention_mask = torch.stack(attention_mask_list)\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Extracting data\n",
    "queries = merged_dataset['SearchQuery'].tolist()\n",
    "domains = merged_dataset[[f'URL{i}Domain' for i in range(1, 6)]].values.tolist()\n",
    "labels = merged_dataset['Labels'].tolist()\n",
    "\n",
    "# Initializing Dataset\n",
    "dataset = URLDomainDataset(queries, domains, labels, tokenizer)\n",
    "\n",
    "# Initializing DataLoader\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "\n",
    "# Assuming you're using a GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=5,  # Assuming you have 5 URL domains to classify per query\n",
    "    problem_type=\"multi_label_classification\",  # Specify the problem type\n",
    ").to(device)\n",
    "\n",
    "# Initialize the AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm  # For nice progress bars\n",
    "\n",
    "# Specify the number of epochs\n",
    "epochs = 3\n",
    "\n",
    "# Use binary cross-entropy with logits as our loss function\n",
    "loss_func = BCEWithLogitsLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(loader, leave=True)  # Create a progress bar\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = loss_func(logits, batch['labels'])\n",
    "        \n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "        loop.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a validation DataLoader named `val_loader`\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Similar loop for validation\n",
    "    # Here, you would calculate your desired metrics based on model predictions\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./BERT_model/model\")\n",
    "tokenizer.save_pretrained(\"./BERT_model/tokenizer\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "URLfinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
